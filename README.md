# FakeNewsDetector
This model uses TfidfVectorizer and a Passive Aggressive Classifier to classify fake news from real news. It is coded in Python. 
**Fake News** is any news that is either factually wrong, misrepresents the facts, and that spreads virally (or maybe to a targeted audience). It can be spread both through regular news mediums or on social media platforms like Facebook, Twitter, WhatsApp, etc.

**Neural fake** news is targeted propaganda that closely mimics the style of real news generated by a neural network. 
Language Modeling is an NLP technique where models learn to predict either the next word or a missing word in a sentence by understanding the context from the sentence itself
By making the model predict either the next word in a sentence or a missing word, we make the model learn the intricacies of the language itself.
The model is able to understand how the grammar works, the different writing styles, etc. And thatâ€™s how the model is able to generate a piece of text that appears credible to the untrained eye. The issue happens when these very same models are used to generate targeted propaganda to confuse people.

There are some incredibly powerful state-of-the-art language models that are really good at generating text.
**1. BERT by Google**
BERT is a language model designed by Google that broke state-of-the-art records. This framework is the reason behind the recent spurt in training and researching large language models by various research labs and companies.
BERT and its counterparts like RoBERTa by Facebook, XLM, XLNet, DistilBERT etc. have performed extremely well on the task of generating text.
 
**2. GPT-2 Models by OpenAI**
The series of language models from OpenAI like GPT, GPT-2, and GPT-Large have created a sensation in the media for their text generation abilities. These are some of the language models we should definitely know about.
 
**3. Grover by AllenNLP**
Grover is an interesting new language model by AllenNLP that has shown great ability to not only generate text but also identify the fake text generated by other models.
One way to identify these machine generated text are to comapare them to another text generator like BERT and then check it is against our text. 
Human generated text has some irregular words which have low probability according to the machine text generators. This is the basic idea behind Fake Image recognition.

**Some Models capable of Detecting fake news are-**
**1)	GPT-2 Detector Model**
**2)	Grover (AllenNLP)**
**3)	FEVER**

# Working of my model
My model Implements a **TfidfVectorizer** . TF (Term Frequency): The number of times a word appears in a document is its Term Frequency. A higher value means a term appears more often than others, and so, the document is a good match when the term is part of the search terms.
IDF (Inverse Document Frequency): Words that occur many times a document, but also occur many times in many others, may be irrelevant. IDF is a measure of how significant a term is in the entire corpus.
The TfidfVectorizer converts a collection of raw documents into a matrix of TF-IDF features.
It then uses a **Passive Aggressive Classifier** to classify the text. Passive Aggressive algorithms are online learning algorithms. Such an algorithm remains passive for a correct classification outcome, and turns aggressive in the event of a miscalculation, updating and adjusting. Unlike most other algorithms, it does not converge. Its purpose is to make updates that correct the loss, causing very little change in the norm of the weight vector.
Using both of them I was able to achieve an accuracy of **92.82%** on the given dataset.

